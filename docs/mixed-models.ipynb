{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mixed models\n",
    "\n",
    "Here, we implement generalized linear mixed effect models (GLMMs), i.e. models of the form:\n",
    "\n",
    "\\begin{align}\\mathbb{E}\\left[ y_{ij} \\mid \\boldsymbol \\gamma_i \\right] &= h \\left( \\boldsymbol \\eta_{ij} \\right) \\\\\n",
    "\\boldsymbol \\eta_{ij} & = \\mathbf{x}_{ij}^T\\boldsymbol \\beta + \\mathbf{u}_{ij}^T \\boldsymbol \\gamma_i\n",
    "\\end{align}\n",
    "\n",
    "for data $(y_{ij}, \\mathbf{x}_{ij})$ that is grouped into $i \\in \\{1, \\dots, m \\}$ groups (or clusters) and $j \\in \\{1, \\dots, n_i\\}$ observations per group. For an intro on the notation, usual assumptions, etc. please refer to _any_ book on regression models, as this is not part of this notebook.\n",
    "\n",
    "In the following we show, how $\\boldsymbol \\beta$ can be estimated and $\\boldsymbol \\gamma$ can be predicted for the Gaussian case and for the Poisson case. The implementations are not really efficient and don't use results from contemporary research (i.e., `lme4`'s PLS and PIRLS). Good references are for instance [McCulloch and Searle (2001)](https://onlinelibrary.wiley.com/doi/book/10.1002/0471722073), [Pinheiro and Bates (2000)](https://link.springer.com/book/10.1007/b98882) and [Jiang (2007)](https://link.springer.com/book/10.1007/978-0-387-47946-0).\n",
    "\n",
    "The relevant code can be found [here](https://github.com/dirmeier/mixed-models).\n",
    "\n",
    "Feedback and comments are welcome!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import scipy.stats as st\n",
    "from patsy import dmatrices\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "rmvnorm = st.multivariate_normal.rvs\n",
    "rpois = st.poisson.rvs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The implementations for fitting GLMMs can be found in these modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lme.ls import working_response, working_weight, irls\n",
    "from lme.marginal_likelhood import restricted_mll\n",
    "from lme.optim import optim\n",
    "from lme.util import block_diag, cholesky_factor, ranef_variance, diag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian LMMs\n",
    "\n",
    "The most prominent example of an LMM is for Gaussian responses $\\mathbf{y}$:\n",
    "\n",
    "\\begin{align}\n",
    "y_{ij} \\mid \\boldsymbol \\gamma_i & \\sim \\mathcal{N}\\left(\\mathbf{x}_{ij}^T\\boldsymbol \\beta + \\mathbf{u}_{ij}^T\\boldsymbol \\gamma_i, \\sigma^2\\right)\\\\\n",
    "\\boldsymbol \\gamma_i & \\sim  \\mathcal{N}\\left(\\mathbf{0}, \\mathbf{Q}\\right)\n",
    "\\end{align}\n",
    "\n",
    "where the response function $h$ is the identity function. This section shows how estimation of the parameters is done in the Gaussian case.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the sleep study data from `lme4` since it's good for our purpose (but any other one will do, too). The description of the data from the package: *The average reaction time per day for subjects in a sleep deprivation study. On day 0 the subjects had their normal amount of sleep. Starting that night they were restricted to 3 hours of sleep per night. The observations represent the average reaction time on a series of tests given each day to each subject.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reaction</th>\n",
       "      <th>Days</th>\n",
       "      <th>Subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>249.5600</td>\n",
       "      <td>0</td>\n",
       "      <td>308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>258.7047</td>\n",
       "      <td>1</td>\n",
       "      <td>308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>250.8006</td>\n",
       "      <td>2</td>\n",
       "      <td>308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>321.4398</td>\n",
       "      <td>3</td>\n",
       "      <td>308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>356.8519</td>\n",
       "      <td>4</td>\n",
       "      <td>308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Reaction  Days  Subject\n",
       "0  249.5600     0      308\n",
       "1  258.7047     1      308\n",
       "2  250.8006     2      308\n",
       "3  321.4398     3      308\n",
       "4  356.8519     4      308"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tab = pd.read_csv(\"./data/sleepstudy.csv\")\n",
    "tab.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `R`'s formula notation we are trying to fit a model of this form: `Reaction ~ Days + (Days | Subject)`. At the time of writing this `patsy` doesn't support creating random effects model matrices, so we need to do it ourselves. However, we can use it for the response matrix and fixed effects design matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, X = dmatrices(\"Reaction ~ Days\", tab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create the random effects matrix $\\mathbf{U}$, let us first realize how $\\mathbf{U}$ has to look: if we collect all cluster-specific responses $\\mathbf{y}_i$ and the respective random effects $\\boldsymbol \\gamma_i$ into vectors, we get\n",
    "\n",
    "\\begin{align}\n",
    "\\mathbf{y} = \n",
    "\\begin{pmatrix}\n",
    "\\mathbf{y}_1 \\\\\n",
    "\\vdots\\\\\n",
    "\\mathbf{y}_m\\\\\n",
    "\\end{pmatrix} =\n",
    "\\begin{pmatrix}\n",
    "y_{1,1}\\\\\n",
    "\\vdots\\\\\n",
    "y_{1,n_1}\\\\\n",
    "y_{2,1}\\\\\n",
    "\\vdots\\\\\n",
    "y_{m,n_m}\n",
    "\\end{pmatrix}\n",
    ",\\qquad\n",
    "\\boldsymbol \\gamma = \n",
    "\\begin{pmatrix}\n",
    "\\boldsymbol \\gamma_{1}\\\\\n",
    "\\vdots\\\\\n",
    "\\boldsymbol \\gamma_{m}\n",
    "\\end{pmatrix}\n",
    "\\end{align}\n",
    "\n",
    "Thus, in matrix notation the general form of $\\mathbf{U}$ needs to be a block diagonal matrix:\n",
    "\n",
    "\\begin{align}\n",
    "\\mathbf{U} = \\text{blockdiag}\\left(\\mathbf{U}_1, \\dots, \\mathbf{U}_i, \\dots ,\\mathbf{U}_m\\right)\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compute $\\mathbf{U}$ using the following method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ranef_model_matrix(tab, factor, ranef):\n",
    "    inter_tab = tab[[factor, ranef]].copy()\n",
    "    inter_tab['grp'] = LabelEncoder().fit_transform(tab.Subject)\n",
    "    inter_tab = inter_tab[[factor, \"grp\"]].pivot(columns=factor).reindex()\n",
    "    inter_tab.values[sp.isfinite(inter_tab.values)] = 1\n",
    "    inter_tab.values[sp.isnan(inter_tab.values)] = 0\n",
    "\n",
    "    slope_tab = tab[[factor, ranef]].copy().pivot(columns=factor).reindex()\n",
    "    slope_tab.values[sp.isnan(slope_tab.values)] = 0\n",
    "\n",
    "    U = pd.concat([inter_tab, slope_tab], axis=1, sort=True)\n",
    "    U = U.reindex(sorted(U.columns, key=lambda x: x[1]), axis=1)\n",
    "\n",
    "    return sp.asarray(U.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 1., 0., ..., 0., 0., 0.],\n",
       "       [1., 2., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 1., 7.],\n",
       "       [0., 0., 0., ..., 0., 1., 8.],\n",
       "       [0., 0., 0., ..., 0., 1., 9.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U = build_ranef_model_matrix(tab, \"Subject\", \"Days\")\n",
    "U"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do some checks: $\\mathbf{U}$ needs to have as many rows as $\\mathbf{X}$ or $\\mathbf{y}$ and twice as many columns as grouping factors, i.e. an intercept and a slope for every group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(U.shape[0] == X.shape[0])\n",
    "assert(U.shape[1] == 2 * len(sp.unique(tab.Subject.values)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will sample the responses ourselves here to be able to validate the inferences. We set $\\sigma^2 = 0.1$ and $\\boldsymbol \\beta = \\left(2 \\ 1\\right)^T$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, p = X.shape\n",
    "q = int(U.shape[1] / 2)\n",
    "\n",
    "sd = 0.1\n",
    "beta = sp.array([2, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we sample every random effects vector $\\boldsymbol \\gamma_i \\sim \\mathcal{N}\\left(\\mathbf{0}, \\sigma^2\\begin{pmatrix} 1 & 0.25 \\\\ 0.25 & 1\\end{pmatrix}\\right)$. Like $\\mathbf{U}$, the covariance matrix of $\\boldsymbol \\gamma$, $\\mathbf{G}$,  has to be block-diagonal, too:\n",
    "\n",
    "\n",
    "\\begin{align}\n",
    "\\mathbf{G} = \\text{blockdiag}\\left(\\mathbf{Q}, \\dots, \\mathbf{Q}, \\dots ,\\mathbf{Q}\\right)\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004416309719067267"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.random.seed(23)\n",
    "\n",
    "Q = sd * sp.array([[1, 0.25], [0.25, 1]])\n",
    "gamma = rmvnorm(mean=sp.zeros(q * 2), cov=block_diag(Q, q))\n",
    "gamma.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then sample from the conditional distribution $P(\\mathbf{y} \\mid \\boldsymbol \\gamma)$ as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = rmvnorm(mean=X.dot(beta) + U.dot(gamma), cov=sp.diag(sd * sp.ones(n)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting an LMM consists of estimating $\\sigma^2$, $\\boldsymbol \\beta$ and $\\mathbf{Q}$ and predicting the random effects $\\boldsymbol \\gamma$. First we estimate $\\sigma^2$ and $\\mathbf{Q}$ by integrating out $\\boldsymbol \\beta$ and $\\boldsymbol \\gamma$ from the conditional likelihood. To do so we treat $\\boldsymbol \\beta$ as a random variable with flat prior as from an empirical Bayes perspective. Having estimated the variance components, we estimate $\\boldsymbol \\beta$ and $\\boldsymbol \\gamma$. \n",
    "\n",
    "More specifically, we start from the joint likelihood of all parameters $L\\left(\\boldsymbol \\beta, \\boldsymbol \\gamma, \\sigma^2, \\mathbf{Q} \\right)$. From this we marginalize out the random effects \n",
    "\n",
    "\\begin{align}\n",
    "L\\left(\\boldsymbol \\beta, \\sigma^2, \\mathbf{Q} \\right) = \\int L\\left(\\boldsymbol \\beta, \\boldsymbol \\gamma, \\sigma^2, \\mathbf{Q} \\right) d\\boldsymbol \\gamma\n",
    "\\end{align}\n",
    "\n",
    "As mentioned above, we now treat $\\boldsymbol \\beta$ as random and marginalize it out, too:\n",
    "\n",
    "\\begin{align}\n",
    "L\\left(\\sigma^2, \\mathbf{Q} \\right) = \\int L\\left(\\boldsymbol \\beta, \\sigma^2, \\mathbf{Q} \\right) d\\boldsymbol \\beta\n",
    "\\end{align}\n",
    "\n",
    "We usually call the likelihood above *restricted* likelihood. $L\\left(\\sigma^2, \\mathbf{Q} \\right)$ needs to be estimated numerically, for instance using Newton's method. We then use [Henderson's mixed model equations](https://en.wikipedia.org/wiki/Mixed_model#Estimation) for $\\boldsymbol \\beta$ and $\\boldsymbol \\gamma$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We optimize the restricted (log)likelihood function first. We define it as a lambda which we can optimize using `scipy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pll = restricted_mll(\"gaussian\")\n",
    "fn = lambda nu, y, X, U: sp.asscalar(pll(nu, y, X, U)[0])\n",
    "\n",
    "opt = optim(fn,\n",
    "            sp.array([2, 5, 0.5, 1]),\n",
    "            ((0.01, None), (None, None), (None, None), (None, None)),\n",
    "            args=(y, X, U))    \n",
    "sd_hat, nu_hat = opt.x[0], opt.x[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimates of $\\sigma^2$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma:\t\t0.1\n",
      "sigma_hat:\t0.10451774782009256\n"
     ]
    }
   ],
   "source": [
    "print(\"sigma:\\t\\t{}\\nsigma_hat:\\t{}\".format(sd, sd_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimates of $\\mathbf{G}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q:\n",
      "[[0.1   0.025]\n",
      " [0.025 0.1  ]]\n",
      "Q_hat:\n",
      "[[0.02451861 0.02563742]\n",
      " [0.02563742 0.11471649]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Q:\\n{}\\nQ_hat:\\n{}\".format(Q, cholesky_factor(nu_hat)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then use Henderson's equations (see McCulloch & Searle (2001), Eqns 6.24 and 6.42):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_hat = ranef_variance(nu_hat, q)\n",
    "R_hat = diag(n, sd_hat)\n",
    "b_hat, gamma_hat = irls(X, U, G_hat, 1/sp.diag(R_hat), y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimates of $\\boldsymbol \\beta$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta: [2 1]\n",
      "beta_hat: [2.02667544 1.01888476]\n"
     ]
    }
   ],
   "source": [
    "print(\"beta: {}\\nbeta_hat: {}\".format(beta, b_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimates of $\\boldsymbol \\gamma$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma:\n",
      "[-0.25538236 -0.07811166 -0.16371937  0.15081283  0.37619662  0.01261309\n",
      " -0.48256002  0.0082431  -0.04384917 -0.30698673  0.06033511  0.46520567\n",
      "  0.27633971 -0.09256565  0.52124719  0.04748265 -0.05064887  0.71172263\n",
      " -0.08712428 -0.79900486  0.125951    0.0477785  -0.27174966 -0.06332042\n",
      " -0.12725791 -0.03387785  0.01130221 -0.04147368  0.22723849  0.29448651\n",
      " -0.02159007  0.526561   -0.25158029  0.03071211 -0.17614052 -0.3882979 ]\n",
      "gamma_hat:\n",
      "[-0.17565207 -0.10253998 -0.00694584  0.08540393  0.11954361  0.04024997\n",
      " -0.06631729 -0.06497658 -0.07201884 -0.31794553  0.1757246   0.42912509\n",
      "  0.02265338 -0.08137199  0.0316269   0.08725347  0.08311083  0.66610281\n",
      " -0.10123518 -0.83483693  0.07952846  0.02856995 -0.11877487 -0.10019238\n",
      " -0.0571625  -0.07433132 -0.06748332 -0.07988322  0.20390674  0.26262008\n",
      "  0.11978779  0.47507794 -0.00283365 -0.02128552 -0.16745874 -0.3970398 ]\n"
     ]
    }
   ],
   "source": [
    "print(\"gamma:\\n{}\\ngamma_hat:\\n{}\".format(gamma, gamma_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statsmodels\n",
    "\n",
    "Let's compare our implementation to `statsmodels`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to set the response to our samples values first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab.Reaction = y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we fit the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Mixed Linear Model Regression Results\n",
      "==========================================================\n",
      "Model:             MixedLM  Dependent Variable:  Reaction \n",
      "No. Observations:  180      Method:              REML     \n",
      "No. Groups:        18       Scale:               0.1045   \n",
      "Min. group size:   10       Likelihood:          -110.6631\n",
      "Max. group size:   10       Converged:           Yes      \n",
      "Mean group size:   10.0                                   \n",
      "----------------------------------------------------------\n",
      "                 Coef. Std.Err.   z    P>|z| [0.025 0.975]\n",
      "----------------------------------------------------------\n",
      "Intercept        2.027    0.058 34.921 0.000  1.913  2.140\n",
      "Days             1.019    0.080 12.693 0.000  0.862  1.176\n",
      "Group Var        0.025    0.068                           \n",
      "Group x Days Cov 0.026    0.065                           \n",
      "Days Var         0.115    0.130                           \n",
      "==========================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "md = smf.mixedlm(\"Reaction ~ Days\", tab, groups=tab[\"Subject\"], re_formula=\"~ Days\")\n",
    "mdf = md.fit()\n",
    "print(mdf.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! Fixed effects look good, and the random effects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma_hat\n",
      "[-0.17565207 -0.10253998 -0.00694584  0.08540393  0.11954361  0.04024997\n",
      " -0.06631729 -0.06497658 -0.07201884 -0.31794553  0.1757246   0.42912509\n",
      "  0.02265338 -0.08137199  0.0316269   0.08725347  0.08311083  0.66610281\n",
      " -0.10123518 -0.83483693  0.07952846  0.02856995 -0.11877487 -0.10019238\n",
      " -0.0571625  -0.07433132 -0.06748332 -0.07988322  0.20390674  0.26262008\n",
      "  0.11978779  0.47507794 -0.00283365 -0.02128552 -0.16745874 -0.3970398 ]\n",
      "gamma_statsmodels:\n",
      "[-0.17566149 -0.10253845 -0.00694846  0.08540437  0.11955076  0.04024881\n",
      " -0.06632019 -0.06497611 -0.07201578 -0.31794607  0.17572583  0.42912494\n",
      "  0.02265696 -0.08137258  0.03162687  0.08725348  0.0830998   0.66610469\n",
      " -0.10122115 -0.83483931  0.07953317  0.02856918 -0.11878046 -0.10019147\n",
      " -0.05716453 -0.07433099 -0.06748593 -0.0798828   0.20391407  0.26261891\n",
      "  0.11978405  0.4750786  -0.00283331 -0.02128558 -0.16746021 -0.39703961]\n"
     ]
    }
   ],
   "source": [
    "print(\"gamma_hat\\n{}\\ngamma_statsmodels:\\n{}\".format(\n",
    "    gamma_hat, sp.concatenate([x.values for x in mdf.random_effects.values()])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Poisson GLMMs\n",
    "\n",
    "A frequently used GLMM in biology which response variable in the exponential family is the Poisson case:\n",
    "\n",
    "\\begin{align}\n",
    "{y}_{ij} \\mid \\boldsymbol \\gamma_i & \\sim \\text{Pois} \\left( \\exp \\left( \\mathbf{x}_{ij}^T\\boldsymbol \\beta + \\mathbf{u}_{ij}^T\\boldsymbol \\gamma_i \\right)\\right)\\\\\n",
    "\\boldsymbol \\gamma_i & \\sim  \\mathcal{N}\\left(\\mathbf{0}, \\mathbf{Q}\\right)\n",
    "\\end{align}\n",
    "\n",
    "where $h$ is, for instance the, exponential function. This section shows how estimation of the parameters is done for Poisson variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, we use the sleep study data from `lme4` and sample the responses ourselves, using the same fixed and random effects matrices and parameters as before. We only change the fixed effects to not get overflows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = sp.array([.25, .5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = rpois(mu=sp.exp(X.dot(beta) + U.dot(gamma)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting an exponential family GLMM is more involved than their Gaussian counterparts, since the integral that marginalizes out $\\boldsymbol \\gamma$ in general does not have a close form solution and the relationship between predictor $\\boldsymbol \\eta$ and the responses $\\mathbf{y}$ is not linear. Otherwise inference is conceptually the same.\n",
    "\n",
    "We start from the restricted likelihood  $L\\left(\\mathbf{Q} \\right)$ and use an Laplace approximation which we maximize to estimate variance components of $\\mathbf{Q}$. Then analogously to normal GLMs, we use IRLS to estimate $\\boldsymbol \\beta$ and $\\boldsymbol \\gamma$. We alternate these steps until converence. You can find more details in the references above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we define the restricted log-likelihood again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pll = restricted_mll(\"poisson\")\n",
    "fn = lambda nu, y, X, U, W, b: sp.asscalar(pll(nu, y, X, U, W, b)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then alternate between estimating the variance components of $\\mathbf{Q}$ and the estimating the fixed and random effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_tilde = bold = sp.ones(shape=p)\n",
    "g_tilde = gold = sp.ones(shape=q * 2)\n",
    "\n",
    "while True:\n",
    "    y_tilde = working_response(y, X, U, b_tilde, g_tilde, sp.exp, sp.exp)\n",
    "    w_tilde = working_weight(y, X, U, b_tilde, g_tilde, sp.exp, sp.exp)\n",
    "    \n",
    "    nu_hat = optim(fn,\n",
    "                   nu_hat,\n",
    "                   bounds=((None, None), (None, None), (None, None)),\n",
    "                   args=(y_tilde, X, U, sp.diag(w_tilde), b_tilde),\n",
    "                   iter=1).x\n",
    "\n",
    "    G_hat = ranef_variance(nu_hat, q)\n",
    "    b_tilde, g_tilde = irls(X, U, G_hat, w_tilde, y_tilde)\n",
    "\n",
    "    if sp.sum((b_tilde - bold) ** 2) < 0.00001 and \\\n",
    "       sp.sum((g_tilde - gold) ** 2) < 0.00001:\n",
    "       break\n",
    "    bold, gold = b_tilde, g_tilde"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimates of $\\boldsymbol \\beta$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta: [0.25 0.5 ]\n",
      "beta_hat: [0.128871   0.54520462]\n"
     ]
    }
   ],
   "source": [
    "print(\"beta: {}\\nbeta_hat: {}\".format(beta, b_tilde))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimates of $\\boldsymbol \\gamma$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma:\n",
      "[-0.25538236 -0.07811166 -0.16371937  0.15081283  0.37619662  0.01261309\n",
      " -0.48256002  0.0082431  -0.04384917 -0.30698673  0.06033511  0.46520567\n",
      "  0.27633971 -0.09256565  0.52124719  0.04748265 -0.05064887  0.71172263\n",
      " -0.08712428 -0.79900486  0.125951    0.0477785  -0.27174966 -0.06332042\n",
      " -0.12725791 -0.03387785  0.01130221 -0.04147368  0.22723849  0.29448651\n",
      " -0.02159007  0.526561   -0.25158029  0.03071211 -0.17614052 -0.3882979 ]\n",
      "gamma_hat:\n",
      "[-0.17565207 -0.10253998 -0.00694584  0.08540393  0.11954361  0.04024997\n",
      " -0.06631729 -0.06497658 -0.07201884 -0.31794553  0.1757246   0.42912509\n",
      "  0.02265338 -0.08137199  0.0316269   0.08725347  0.08311083  0.66610281\n",
      " -0.10123518 -0.83483693  0.07952846  0.02856995 -0.11877487 -0.10019238\n",
      " -0.0571625  -0.07433132 -0.06748332 -0.07988322  0.20390674  0.26262008\n",
      "  0.11978779  0.47507794 -0.00283365 -0.02128552 -0.16745874 -0.3970398 ]\n"
     ]
    }
   ],
   "source": [
    "print(\"gamma:\\n{}\\ngamma_hat:\\n{}\".format(gamma, gamma_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statsmodels\n",
    "\n",
    "Afaik `statsmodels` does not have implementations for frequentist GLMMS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## License\n",
    "\n",
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc/4.0/\"><img align=\"left\" alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-nc/4.0/88x31.png\" /></a> <br>\n",
    "\n",
    "\n",
    "The case study is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc/4.0/\">Creative Commons Attribution-NonCommercial 4.0 International License</a>."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
